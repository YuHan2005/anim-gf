# æ–‡ä»¶å: main.py
# -*- coding: utf-8 -*-
import os
import sys
from gen_image import generate_static_image
from animate_only import AnimationEngine

# ===================== ğŸ”§ ç»ˆæé…ç½® =====================
# 1. æ¨¡å‹è·¯å¾„
BASE_MODEL = r"E:\huggingface_cache\Counterfeit-V3.0\Counterfeit-V3.0_fix_fp16.safetensors"
MOTION_MODULE = r"E:\huggingface_cache\animatediff-motion-adapter-v1-5-3"
IP_ADAPTER = r"E:\huggingface_cache\IP-Adapter"

# 2. æ’ä»¶è·¯å¾„ (æŒ‡å‘åŒ…å« config.json å’Œ safetensors çš„æ–‡ä»¶å¤¹)
VAE_PATH = r"E:\huggingface_cache\vae" 
EMBEDDING_PATH = r"E:\huggingface_cache\embeddings\easynegative.safetensors"

# 3. è¾“å‡ºé…ç½®
OUTPUT_DIR = "output"
# ==========================================================

def main():
    print("=== è™šæ‹Ÿå¥³å‹ç”Ÿæˆå™¨ (å¤–æŒ‚VAEç‰ˆ) ===")
    
    # è·¯å¾„è‡ªæ£€
    for p in [BASE_MODEL, MOTION_MODULE, IP_ADAPTER, VAE_PATH]:
        if not os.path.exists(p):
            print(f"âŒ ä¸¥é‡é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶æˆ–ç›®å½•: {p}")
            return

    current_image_path = ""
    Create_image = True
    preview_path = os.path.join(OUTPUT_DIR, "preview_wife.png")
        
    if os.path.exists(preview_path):
        Create_image = False
        user_input = input(">> [ç³»ç»Ÿ] æ£€æµ‹åˆ°å·²æœ‰å›¾ç‰‡ï¼Œæ˜¯å¦éœ€è¦é‡æ–°ç”Ÿæˆã€‚(Y/N)? :").lower()
        if user_input == 'y':
            try:
                os.remove(preview_path)
            except OSError:
                pass 
            Create_image = True
        else:
            Create_image = False
            current_image_path = preview_path

    # æç¤ºè¯
    base_prompt = "masterpiece, best quality, 1girl, silver hair, red eyes, white dress, upper body, gentle smile, looking at viewer, highres, solo, big breast, sexy expression"
    neg_prompt = (
            "easynegative, (low quality, worst quality:1.4), (bad anatomy), (inaccurate limb:1.2), "
            "bad composition, inaccurate eyes, extra digit, fewer digits, (extra arms:1.2), "
            "bad hands, missing fingers, extra limbs, "
            "blurry, ugly, deformed, noisy, texture, jpeg artifacts, signature, watermark"
        )
    
    # --- é˜¶æ®µä¸€ï¼šæŠ½å¡ ---
    while Create_image:
        current_image_path = generate_static_image(
            base_model_path=BASE_MODEL,
            vae_path=VAE_PATH,          # ä¼ å…¥å¤–éƒ¨ VAE
            embedding_path=EMBEDDING_PATH, 
            prompt=base_prompt,
            neg_prompt=neg_prompt,
            output_dir=OUTPUT_DIR,
            filename="preview_wife.png"
        )
        
        print(f"\nè¯·æŸ¥çœ‹é¢„è§ˆå›¾: {current_image_path}")
        user_input = input(">> æ»¡æ„å—ï¼Ÿ(Enter: ç»§ç»­ / r: é‡æŠ½ / q: é€€å‡º): ").lower()
        
        if user_input == 'q': sys.exit()
        elif user_input == 'r': continue
        else: break 

    # --- é˜¶æ®µäºŒï¼šè®¾ç½®æ—¶é•¿ ---
    print("\n" + "-"*30)
    print(">> è¯·è®¾ç½®è§†é¢‘å‚æ•°")
    try:
        user_frames = input(">> è¯·è¾“å…¥ç”Ÿæˆå¸§æ•° [é»˜è®¤ä¸º16]: ")
        num_frames = int(user_frames) if user_frames.strip() else 16
        if num_frames > 32: num_frames = 32
    except ValueError:
        num_frames = 16

    # åŠ¨ç”»å¼•æ“åˆå§‹åŒ–
    print("\n>> æ­£åœ¨åˆå§‹åŒ–åŠ¨ç”»å¼•æ“...")
    engine = AnimationEngine(
        base_model_path=BASE_MODEL,
        motion_module_path=MOTION_MODULE,
        ip_adapter_path=IP_ADAPTER,
        vae_path=VAE_PATH,              # ä¼ å…¥å¤–éƒ¨ VAE
        embedding_path=EMBEDDING_PATH   
    )
    
    action_prompt = f"{base_prompt}, reading book, turning page, wind blowing hair, upper body, detailed face"
    
    final_gif_path = os.path.join(OUTPUT_DIR, f"final_wife_{num_frames}frames.gif")
    
    engine.run(
        image_path=current_image_path,
        action_prompt=action_prompt,
        neg_prompt=neg_prompt,
        output_path=final_gif_path,
        num_frames=num_frames,
        fps=8 
    )
    
    print("\n>> å…¨éƒ¨æµç¨‹ç»“æŸï¼")

if __name__ == "__main__":
    main()