import streamlit as st
import base64
import os
import time
import re  # æ­£åˆ™åº“
from language.brain import AIBrain
from speech.voice import AIVoice

# ================= ğŸ”§ é…ç½®è·¯å¾„ =================
OUTPUT_DIR = "output_chat"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

TEMPLATE_VIDEO = os.path.join(OUTPUT_DIR, "template_idle.mp4")
AVATAR_PATH = os.path.join(OUTPUT_DIR, "avatar_base.png")

# ç”¨æˆ·å¤´åƒ
USER_AVATAR_URL = "https://api.dicebear.com/7.x/adventurer/svg?seed=Felix"

# ================= ğŸ¨ é¡µé¢è®¾ç½® =================
st.set_page_config(
    page_title="æˆ‘çš„å¥³å‹: å°çˆ±",
    page_icon="ğŸ’–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ================= ğŸ› ï¸ å·¥å…·å‡½æ•° =================
def get_img_as_base64(file_path):
    with open(file_path, "rb") as f:
        data = f.read()
    return base64.b64encode(data).decode()

def clean_text_for_speech(text):
    """
    æ¸…æ´—æ–‡æœ¬ï¼šå»é™¤ *åŠ¨ä½œæå†™* å’Œ (å¿ƒç†æ´»åŠ¨)ï¼Œåªä¿ç•™æƒ³è¯´çš„è¯
    """
    # 1. å»é™¤ *...* ä¹‹é—´çš„å†…å®¹ (å…¼å®¹æ—§æ ¼å¼)
    text = re.sub(r'\*.*?\*', '', text)
    # 2. å»é™¤ (...) è‹±æ–‡æ‹¬å·
    text = re.sub(r'\(.*?\)', '', text)
    # 3. å»é™¤ ï¼ˆ...ï¼‰ ä¸­æ–‡æ‹¬å· (é˜²æ­¢AIå¶å°”ä¸å¬è¯)
    text = re.sub(r'ï¼ˆ.*?ï¼‰', '', text)
    
    # 4. å»é™¤å¤šä½™ç©ºæ ¼
    return text.strip()

# é¢„åŠ è½½å¤´åƒ
if os.path.exists(AVATAR_PATH):
    img_b64 = get_img_as_base64(AVATAR_PATH)
    AI_AVATAR_HTML = f"data:image/png;base64,{img_b64}"
else:
    AI_AVATAR_HTML = "https://api.dicebear.com/7.x/avataaars/svg?seed=Coco"

# ================= ğŸ’„ CSS æ ·å¼ =================
st.markdown("""
<style>
    .stApp { background-color: #f5f5f5; }
    .chat-row { display: flex; align-items: flex-start; margin-bottom: 20px; width: 100%; }
    .avatar { width: 50px; height: 50px; border-radius: 6px; object-fit: cover; box-shadow: 0 1px 3px rgba(0,0,0,0.2); }
    .bubble { padding: 10px 14px; border-radius: 6px; position: relative; max-width: 70%; word-wrap: break-word; font-size: 16px; line-height: 1.6; box-shadow: 0 1px 2px rgba(0,0,0,0.1); }
    .row-ai { justify-content: flex-start; }
    .bubble-ai { background-color: #ffffff; color: #000; margin-left: 12px; border: 1px solid #ededed; }
    .bubble-ai::before { content: ""; position: absolute; left: -6px; top: 16px; width: 0; height: 0; border-top: 6px solid transparent; border-bottom: 6px solid transparent; border-right: 6px solid #ffffff; }
    .row-user { justify-content: flex-end; }
    .bubble-user { background-color: #95ec69; color: #000; margin-right: 12px; }
    .bubble-user::before { content: ""; position: absolute; right: -6px; top: 16px; width: 0; height: 0; border-top: 6px solid transparent; border-bottom: 6px solid transparent; border-left: 6px solid #95ec69; }
    footer {visibility: hidden;}
    #MainMenu {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ================= ğŸ§  æ ¸å¿ƒåŠ è½½ =================
@st.cache_resource
def load_brain():
    return AIBrain()

@st.cache_resource
def load_voice():
    return AIVoice()

if "messages" not in st.session_state:
    st.session_state.messages = []

# ================= ğŸ“± ä¾§è¾¹æ  =================
with st.sidebar:
    st.title("ğŸ’– ä½ çš„å¥³å‹")
    if os.path.exists(TEMPLATE_VIDEO):
        st.video(TEMPLATE_VIDEO, autoplay=True, loop=True, muted=True)
    elif os.path.exists(AVATAR_PATH):
        st.image(AVATAR_PATH)
    st.markdown("---")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºèŠå¤©è®°å½•", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# ================= ğŸ’¬ èŠå¤©ç•Œé¢ =================
st.header("ğŸ’¬ ç”œèœœå¯¹è¯")
chat_container = st.container()

with chat_container:
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            st.markdown(f"""<div class="chat-row row-user"><div class="bubble bubble-user">{msg["content"]}</div><img class="avatar" src="{USER_AVATAR_URL}"></div>""", unsafe_allow_html=True)
        else:
            st.markdown(f"""<div class="chat-row row-ai"><img class="avatar" src="{AI_AVATAR_HTML}"><div class="bubble bubble-ai">{msg["content"]}</div></div>""", unsafe_allow_html=True)
            if "audio" in msg and msg["audio"]:
                 st.audio(msg["audio"], format="audio/wav")

# ================= âš¡ äº¤äº’é€»è¾‘ =================
if user_input := st.chat_input("æƒ³å¯¹å¥¹è¯´ç‚¹ä»€ä¹ˆ..."):
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    with chat_container:
        message_placeholder = st.empty()
        # å…ˆæ˜¾ç¤ºæ€è€ƒä¸­
        message_placeholder.markdown(f"""<div class="chat-row row-ai"><img class="avatar" src="{AI_AVATAR_HTML}"><div class="bubble bubble-ai" style="color:gray;"><i>(æ­£åœ¨æ€è€ƒ...)</i></div></div>""", unsafe_allow_html=True)
        
        # 1. ç”Ÿæˆæ–‡å­—
        brain = load_brain()
        full_response = brain.chat(st.session_state.messages[-1]["content"])
        
        # ç«‹å³æ˜¾ç¤ºæ–‡å­—ç»“æœ
        message_placeholder.markdown(f"""<div class="chat-row row-ai"><img class="avatar" src="{AI_AVATAR_HTML}"><div class="bubble bubble-ai">{full_response}</div></div>""", unsafe_allow_html=True)
        
        # 2. å¤„ç†è¯­éŸ³
        voice = load_voice()
        
        # æ¸…æ´—åŠ¨ä½œæè¿° (æ”¯æŒä¸­è‹±æ–‡æ‹¬å·)
        spoken_text = clean_text_for_speech(full_response)
        
        if not spoken_text: 
            spoken_text = "å—¯~" 
            
        # ç”ŸæˆåŠ¨æ€æ–‡ä»¶å
        # 1. ç”Ÿæˆæ–‡ä»¶åæ—¶ï¼Œç›´æ¥ç”¨ .wav
        temp_filename = os.path.join(OUTPUT_DIR, f"audio_{int(time.time())}.wav")
        
        # 2. è°ƒç”¨ç”Ÿæˆï¼Œå¹¶æ¥æ”¶è¿”å›çš„â€œçœŸå®è·¯å¾„â€ (voice.py å¯èƒ½ä¼šä¿®æ­£è·¯å¾„ï¼Œæ‰€ä»¥è¦æ¥ä½è¿”å›å€¼)
        real_filepath = voice.speak(spoken_text, output_file=temp_filename)
        
        # 3. è¯»å–éŸ³é¢‘ (è¯»å– voice.speak è¿”å›çš„é‚£ä¸ªçœŸå®è·¯å¾„)
        audio_data = None
        # åªæœ‰å½“æ–‡ä»¶è·¯å¾„å­˜åœ¨ï¼Œä¸”æ–‡ä»¶çœŸçš„åœ¨ç¡¬ç›˜ä¸Šæ—¶æ‰è¯»å–
        if real_filepath and os.path.exists(real_filepath):
            with open(real_filepath, "rb") as f:
                audio_data = f.read()
            try:
                os.remove(real_filepath) # è¯»å®Œå³ç„š
            except:
                pass
        else:
            print(f"!! [è°ƒè¯•] ç½‘é¡µç«¯æ²¡æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶: {temp_filename}")
        
        # 4. ä¿å­˜åˆ°å†å²
        st.session_state.messages.append({
            "role": "assistant", 
            "content": full_response,
            "audio": audio_data 
        })
        
        message_placeholder.empty()
        st.rerun()