# -*- coding: utf-8 -*-
import os
import time
import subprocess
import platform

# å¯¼å…¥æˆ‘ä»¬ä¹‹å‰å†™å¥½çš„æ‰€æœ‰æ¨¡å—
from language.brain import AIBrain
from speech.voice import AIVoice
from lip.lipsync import LipSyncEngine
from generate_image.gen_image import generate_static_image
from generate_image.animate_only import AnimationEngine

# ================= ğŸ”§ å…¨å±€é…ç½®è·¯å¾„ =================
BASE_MODEL = r"E:\huggingface_cache\hassaku\hassakuSD15_v13.safetensors"
MOTION_MODULE = r"E:\huggingface_cache\animatediff-motion-adapter-v1-5-3"
IP_ADAPTER = r"E:\huggingface_cache\IP-Adapter"
VAE_PATH = r"E:\huggingface_cache\vae" 
EMBEDDING_PATH = r"E:\huggingface_cache\embeddings\easynegative.safetensors"

OUTPUT_DIR = "output_chat"
AVATAR_IMG = os.path.join(OUTPUT_DIR, "avatar_base.png")
TEMPLATE_VIDEO = os.path.join(OUTPUT_DIR, "template_idle.mp4")
AUDIO_TEMP = os.path.join(OUTPUT_DIR, "response_audio.mp3")
# ======================================================

def open_video(path):
    """è·¨å¹³å°æ‰“å¼€è§†é¢‘æ–‡ä»¶"""
    try:
        if platform.system() == "Windows":
            os.startfile(path)
        elif platform.system() == "Darwin":
            subprocess.call(["open", path])
        else:
            subprocess.call(["xdg-open", path])
    except Exception as e:
        print(f"æ‰“å¼€è§†é¢‘å¤±è´¥: {e}")

def main():
    print("=== ğŸ¤– AI å¥³å‹ (æé€Ÿè¯­éŸ³ç‰ˆ) å¯åŠ¨ä¸­... ===")
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # ==========================================
    # ğŸš€ é˜¶æ®µä¸€ï¼šè§†è§‰å½¢è±¡ (ä¿ç•™ä½œä¸ºåŠ¨æ€å£çº¸)
    # ==========================================
    need_init_visuals = not os.path.exists(TEMPLATE_VIDEO)
    
    if need_init_visuals:
        print("\n[1/3] æ­£åœ¨ç”Ÿæˆå¥³å‹çš„åŠ¨æ€å½¢è±¡ (ä»…éœ€ä¸€æ¬¡)...")
        
        # A. ç”Ÿæˆé™æ€å›¾
        if not os.path.exists(AVATAR_IMG):
            # ç¨³é‡çš„ Prompt
            prompt = (
                "masterpiece, best quality, 1girl, solo, silver hair, red eyes, "
                "white dress, looking at viewer, shy, blushing, upper body, "
                "soft lighting, high resolution, closed mouth, smile" 
            )
            neg_prompt = "easynegative, nsfw, worst quality, low quality, open mouth"
            
            print("   >> æ­£åœ¨ç»˜åˆ¶å¥³å‹ç…§ç‰‡...")
            generate_static_image(
                base_model_path=BASE_MODEL,
                vae_path=VAE_PATH,
                embedding_path=EMBEDDING_PATH,
                prompt=prompt,
                neg_prompt=neg_prompt,
                output_dir=OUTPUT_DIR,
                filename="avatar_base.png"
            )
        
        # B. ç”Ÿæˆå¾…æœºåŠ¨ç”»
        print("   >> æ­£åœ¨ç”Ÿæˆå¾…æœºåŠ¨ä½œè§†é¢‘...")
        animator = AnimationEngine(
            base_model_path=BASE_MODEL,
            motion_module_path=MOTION_MODULE,
            ip_adapter_path=IP_ADAPTER,
            vae_path=VAE_PATH,
            embedding_path=EMBEDDING_PATH
        )
        
        # ä½¿ç”¨ç¨³é‡çš„åŠ¨ä½œ Prompt
        animator.run(
            image_path=AVATAR_IMG,
            action_prompt="best quality, 1girl, static pose, breathing, blinking, looking at viewer, minimal head movement",
            neg_prompt="worst quality, low quality, distortion, morphing, open mouth",
            output_path=TEMPLATE_VIDEO,
            num_frames=16, 
            fps=8
        )
        del animator
    else:
        print("\n[1/3] âœ… å½¢è±¡å·²å‡†å¤‡å°±ç»ªï¼")
        # å¯åŠ¨æ—¶è‡ªåŠ¨æ‰“å¼€è¿™ä¸ªè§†é¢‘ï¼Œç”¨æˆ·å¯ä»¥æ‰‹åŠ¨è®¾ç½®å¾ªç¯æ’­æ”¾ï¼Œå‡è£…å¥¹åœ¨å¬
        print(">> æ­£åœ¨æ‰“å¼€å¾…æœºè§†é¢‘ï¼Œè¯·å°†å…¶è®¾ç½®ä¸ºã€å¾ªç¯æ’­æ”¾ã€‘...")
        open_video(TEMPLATE_VIDEO)

    # ==========================================
    # ğŸš€ é˜¶æ®µäºŒï¼šåŠ è½½æ ¸å¿ƒæ¨¡å—
    # ==========================================
    print("\n[2/3] æ­£åœ¨å”¤é†’å¤§è„‘ (Llama-3)...")
    brain = AIBrain()
    
    print("\n[3/3] æ­£åœ¨å‡†å¤‡å£°éŸ³ (EdgeTTS)...")
    voice = AIVoice()
    
    # âŒ åˆ é™¤äº† Wav2Lip åŠ è½½

    # ==========================================
    # ğŸš€ é˜¶æ®µä¸‰ï¼šæé€ŸèŠå¤©å¾ªç¯
    # ==========================================
    print("\n" + "="*40)
    print("ğŸ’– å¥³å‹å·²ä¸Šçº¿ï¼(å“åº”é€Ÿåº¦å·²å¤§å¹…æå‡)")
    print("="*40)

    while True:
        user_input = input("\nğŸ‘¤ ä½ : ")
        
        if user_input.lower() in ['q', 'exit']:
            break
        if user_input.lower() == 'reset':
            print(">> [æŒ‡ä»¤] åˆ é™¤æ—§å½¢è±¡...")
            if os.path.exists(TEMPLATE_VIDEO): os.remove(TEMPLATE_VIDEO)
            if os.path.exists(AVATAR_IMG): os.remove(AVATAR_IMG)
            break 

        # A. æ€è€ƒ (ç§’å›)
        start_time = time.time()
        reply_text = brain.chat(user_input)
        
        # æ¸…ç†æ–‡æœ¬
        spoken_text = reply_text.split('*')[0].split('(')[0]
        if not spoken_text.strip(): spoken_text = "å—¯..."
        
        print(f"ğŸ‘© å°çˆ±: {reply_text}")

        # B. é…éŸ³ (ç§’å›)
        # è¿™ä¸€æ­¥ä¼šè‡ªåŠ¨æ’­æ”¾å£°éŸ³
        voice.speak(spoken_text, output_file=AUDIO_TEMP)

        cost_time = time.time() - start_time
        print(f">> [è€—æ—¶] å“åº”è€—æ—¶: {cost_time:.2f}ç§’")
        
        # âŒ ä¸å†è°ƒç”¨ Wav2Lipï¼Œä¹Ÿä¸å†å¼¹çª—è§†é¢‘

if __name__ == "__main__":
    main()